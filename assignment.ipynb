{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2a1cdd6",
   "metadata": {
    "problem_id": "ex1"
   },
   "source": [
    "## **Exercise 1**\n",
    "<!-- @q -->\n",
    "\n",
    "In the following exercises, we'll explore the behavior of different ensemble methods from the notes. First, we'll set up some synthetic data to play with.  I've included a decision tree classifier to provide you with a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d31fef",
   "metadata": {
    "part_id": "ex1-part1",
    "span": "ex1-part1.code",
    "student": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01d1c1a",
   "metadata": {
    "part_id": "ex1-part2"
   },
   "source": [
    "### **Exercise 1.1**\n",
    "\n",
    "Implement a bagging classifier with 10 decision tree estimators, and compare performance to the single decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e7cddd",
   "metadata": {
    "part_id": "ex1-part2",
    "span": "ex1-part2.code",
    "student": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf364693",
   "metadata": {
    "part_id": "ex1-part3"
   },
   "source": [
    "### **Exercise 1.2: Effect of Subsampling in Bagging**\n",
    "\n",
    "\n",
    "__Task:__\n",
    "\n",
    "- Train a BaggingClassifier with different max_samples values (30%, 50%, 70% and 100%) and compare how subsampling affects the modelâ€™s performance on the test set.\n",
    "- Use 10 base estimators as in Exercise 1.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4867954e",
   "metadata": {
    "part_id": "ex1-part3",
    "span": "ex1-part3.code",
    "student": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762fbe13",
   "metadata": {},
   "source": [
    "### **Exercise 1.3: Out-of-Bag (OOB) Evaluation**\n",
    "\n",
    "<!-- @sub-->\n",
    "\n",
    "**Task:**\n",
    "\n",
    "- Enable Out-of-Bag (OOB) evaluation in the BaggingClassifier and compare the OOB score to the test set accuracy.\n",
    "- Train the model using 10 base estimators and the same synthetic dataset as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df86b89f",
   "metadata": {
    "part_id": "ex1-part3",
    "span": "ex1-part3.code",
    "student": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051799cd",
   "metadata": {
    "part_id": "ex1-part4"
   },
   "source": [
    "### **Exercise 1.4: Implementing AdaBoost**\n",
    "\n",
    "\n",
    "**Task:**  \n",
    "- Train an `AdaBoostClassifier` using 10 estimators and a learning rate of 1.\n",
    "- Use the synthetic dataset from earlier exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cb71d2",
   "metadata": {
    "part_id": "ex1-part4",
    "span": "ex1-part4.code",
    "student": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68b8cbb",
   "metadata": {
    "part_id": "ex1-part5"
   },
   "source": [
    "### **Exercise 1.5: Effect of Hyperparameters in AdaBoost**\n",
    "\n",
    "\n",
    "**Task:**  \n",
    "- Sweep the learning rate parameters from .5 to 2 in increments of .25, and the number of estimators from 5 to 55 in increments of 10. Use cross validation with accuracy to evaluate performance. \n",
    "- Use GridSearchCV for your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3468ee5",
   "metadata": {
    "part_id": "ex1-part5",
    "span": "ex1-part5.code",
    "student": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803bf8e6",
   "metadata": {},
   "source": [
    "<!-- @ sub -->\n",
    "Which parameters perform best? Which are the worst?  Do your results surprise you?  Why do you think you are seeing what you do?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c252eb",
   "metadata": {
    "part_id": "ex1-part5",
    "span": "ex1-part5.answer",
    "student": true
   },
   "source": [
    "*Enter your answer in this cell*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df56198b",
   "metadata": {
    "problem_id": "ex2"
   },
   "source": [
    "# **Exercise 2: Gradient Boosting for Regression**\n",
    "\n",
    "\n",
    "- Use `sklearn.ensemble.GradientBoostingRegressor` to implement a regression model on the following dataset.\n",
    "- Use a single train / test split\n",
    "- Train the model with 50 estimators and compare its performance to a decision tree regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c15b2b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @SHOW\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Generate synthetic regression dataset\n",
    "X_reg, y_reg = make_regression(n_samples=1000, n_features=2, noise=0.1, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cd8251",
   "metadata": {
    "part_id": "ex2-part1",
    "span": "ex2-part1.code",
    "student": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c8b35a",
   "metadata": {
    "problem_id": "ex3"
   },
   "source": [
    "# **Exercise 3**\n",
    "\n",
    "<!-- @q -->\n",
    "\n",
    "Previously, we used hyperparameter optimization to optimize clustering.  Here, we will use it to optimize a random forest classifier.   I've started the process by organizing the data and establishing a baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002c3e01",
   "metadata": {
    "part_id": "ex3-part1",
    "span": "ex3-part1.code",
    "student": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c668c1d2",
   "metadata": {
    "part_id": "ex3-part2"
   },
   "source": [
    "#### Step 1: GridSearchCV\n",
    "\n",
    "\n",
    "Implement run a grid search (using GridSearchCV) over a range of parameters for the random forest on the previously established data.  Test at least 18 different parameter combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8e8405",
   "metadata": {
    "part_id": "ex3-part2",
    "span": "ex3-part2.code",
    "student": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7977c9",
   "metadata": {
    "part_id": "ex3-part3"
   },
   "source": [
    "#### Step 2: RandomizedSearchCV\n",
    "\n",
    "\n",
    "Implement run a random search (using RandomSearchCV) over a range of parameters for the random forest.  Test at least 20 different parameter combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0382838",
   "metadata": {
    "part_id": "ex3-part3",
    "span": "ex3-part3.code",
    "student": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1828bcc",
   "metadata": {
    "part_id": "ex3-part4"
   },
   "source": [
    "#### Step 3: BayesianSearchCV\n",
    "\n",
    "\n",
    "\n",
    "Previously, we used HyperOpt for Bayesian optimization. The [bayesian-optimization](https://pypi.org/project/bayesian-optimization/) does much the same thing, but is a little more user friendly. Install the package and use it to run a Bayesian search over a range of parameters for the random forest.  Test at least 15 different parameter combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e20e38",
   "metadata": {
    "part_id": "ex3-part4",
    "span": "ex3-part4.code",
    "student": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a0c74f",
   "metadata": {
    "part_id": "ex3-part5"
   },
   "source": [
    "#### Step 4: Compare and Reflect\n",
    "\n",
    "\n",
    "Compare the outputs of the different strategies.  Do they converge to similar parameters?  Why or why not?  Which method would you try first in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b8f333",
   "metadata": {
    "part_id": "ex3-part5",
    "span": "ex3-part5.answer",
    "student": true
   },
   "source": [
    "*Enter your answer in this cell*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
